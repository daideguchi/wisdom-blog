#!/usr/bin/env python3
"""
Zennæœ€é©åŒ–AIè¨˜äº‹ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Zennç‰¹åŒ–ã®è¨˜äº‹ç”Ÿæˆãƒ»å“è³ªãƒã‚§ãƒƒã‚¯ãƒ»è‡ªå‹•æŠ•ç¨¿ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
import frontmatter
import re
import requests
from datetime import datetime, timedelta
from pathlib import Path
from anthropic import Anthropic
from typing import Dict, List, Optional, Any

# è¨­å®š
OBSIDIAN_VAULT_PATH = "/Users/dd/Library/Mobile Documents/iCloud~md~obsidian/Documents"
DEV_LOGS_PATH = os.path.join(OBSIDIAN_VAULT_PATH, "01_Dev_Logs")
PROJECT_ARTICLES_PATH = "/Users/dd/Desktop/1_dev/coding-rule2/projects/post_tool/articles"
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# Zennæœ€é©åŒ–è¨­å®š
ZENN_OPTIMAL_CONFIG = {
    "min_word_count": 800,
    "max_word_count": 4000,
    "optimal_word_count": 1500,
    "max_topics": 5,
    "min_topics": 2,
    "supported_types": ["tech", "idea"],
    "quality_threshold": 0.8
}

# Zennäººæ°—Topicãƒãƒƒãƒ”ãƒ³ã‚°
ZENN_POPULAR_TOPICS = {
    "python": ["python", "fastapi", "django", "flask", "pandas"],
    "javascript": ["javascript", "nodejs", "react", "vue", "nextjs"],
    "typescript": ["typescript", "react", "nodejs", "frontend"],
    "ai": ["machinelearning", "ai", "python", "tensorflow", "pytorch"],
    "web": ["frontend", "backend", "webdev", "css", "html"],
    "cloud": ["aws", "gcp", "azure", "docker", "kubernetes"],
    "mobile": ["flutter", "reactnative", "ios", "android"],
    "data": ["data", "sql", "analytics", "visualization"]
}

# æŠ€è¡“åˆ¥æœ€é©emoji
TECH_EMOJIS = {
    "python": "ğŸ", "javascript": "ğŸŸ¨", "typescript": "ğŸ”·", "react": "âš›ï¸",
    "vue": "ğŸ’š", "ai": "ğŸ¤–", "ml": "ğŸ§ ", "data": "ğŸ“Š", "web": "ğŸŒ",
    "cloud": "â˜ï¸", "docker": "ğŸ³", "git": "ğŸ“", "api": "ğŸ”Œ",
    "database": "ğŸ—„ï¸", "security": "ğŸ”’", "performance": "âš¡", "testing": "ğŸ§ª"
}

class ZennOptimizedGenerator:
    def __init__(self):
        self.client = Anthropic(api_key=ANTHROPIC_API_KEY) if ANTHROPIC_API_KEY else None
        self.ensure_folders()
        
    def ensure_folders(self):
        """å¿…è¦ãªãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"""
        os.makedirs(PROJECT_ARTICLES_PATH, exist_ok=True)
        
    def get_recent_logs(self, days: int = 7) -> List[Dict[str, Any]]:
        """æœ€è¿‘ã®ãƒ­ã‚°ã‚’å–å¾—"""
        all_logs = []
        
        for i in range(days):
            date = datetime.now() - timedelta(days=i)
            log_file = os.path.join(DEV_LOGS_PATH, f"dev_log_{date.strftime('%Y-%m-%d')}.json")
            
            if os.path.exists(log_file):
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        daily_logs = json.load(f)
                        all_logs.extend(daily_logs)
                except Exception as e:
                    print(f"ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({log_file}): {e}")
        
        return all_logs
    
    def analyze_technical_domains(self, logs: List[Dict]) -> Dict[str, Any]:
        """æŠ€è¡“ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’åˆ†æã—ã¦Zennæœ€é©ãªãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
        tech_analysis = {
            "primary_tech": set(),
            "secondary_tech": set(),
            "frameworks": set(),
            "tools": set(),
            "patterns": [],
            "complexity_level": "beginner"
        }
        
        tech_indicators = {
            "python": ["python", ".py", "pip", "venv", "django", "flask", "fastapi"],
            "javascript": ["javascript", ".js", "npm", "node", "yarn"],
            "typescript": ["typescript", ".ts", ".tsx", "tsc"],
            "react": ["react", "jsx", "useState", "useEffect", "component"],
            "ai": ["ai", "ml", "model", "training", "tensorflow", "pytorch", "claude", "openai"],
            "web": ["html", "css", "frontend", "backend", "api", "server"],
            "cloud": ["aws", "docker", "kubernetes", "deployment", "cloud"],
            "data": ["database", "sql", "pandas", "analytics", "visualization"]
        }
        
        # ãƒ­ã‚°ã‹ã‚‰æŠ€è¡“ã‚’æŠ½å‡º
        all_text = " ".join([
            log.get("message", "") + " " + str(log.get("details", {}))
            for log in logs
        ]).lower()
        
        for tech, keywords in tech_indicators.items():
            matches = sum(1 for keyword in keywords if keyword in all_text)
            if matches >= 3:
                tech_analysis["primary_tech"].add(tech)
            elif matches >= 1:
                tech_analysis["secondary_tech"].add(tech)
        
        # è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«åˆ¤å®š
        advanced_indicators = ["architecture", "optimization", "performance", "scale", "system"]
        if any(indicator in all_text for indicator in advanced_indicators):
            tech_analysis["complexity_level"] = "advanced"
        elif len(tech_analysis["primary_tech"]) > 2:
            tech_analysis["complexity_level"] = "intermediate"
        
        return tech_analysis
    
    def select_optimal_emoji(self, tech_analysis: Dict[str, Any]) -> str:
        """æŠ€è¡“åˆ†æã«åŸºã¥ã„ã¦æœ€é©ãªemojiã‚’é¸æŠ"""
        primary_techs = tech_analysis["primary_tech"]
        
        # å„ªå…ˆåº¦ã®é«˜ã„æŠ€è¡“ã‹ã‚‰é¸æŠ
        for tech in ["ai", "python", "react", "typescript", "javascript"]:
            if tech in primary_techs:
                return TECH_EMOJIS.get(tech, "ğŸ“")
        
        return "ğŸš€"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def generate_zenn_topics(self, tech_analysis: Dict[str, Any]) -> List[str]:
        """Zennäººæ°—ãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰æœ€é©ãªãƒˆãƒ”ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        topics = []
        primary_techs = tech_analysis["primary_tech"]
        secondary_techs = tech_analysis["secondary_tech"]
        
        # ä¸»è¦æŠ€è¡“ã‹ã‚‰å¿…é ˆãƒˆãƒ”ãƒƒã‚¯
        for tech in primary_techs:
            if tech in ZENN_POPULAR_TOPICS:
                topics.extend(ZENN_POPULAR_TOPICS[tech][:2])
        
        # å‰¯æ¬¡æŠ€è¡“ã‹ã‚‰è£œå®Œ
        for tech in secondary_techs:
            if tech in ZENN_POPULAR_TOPICS and len(topics) < 4:
                topics.append(ZENN_POPULAR_TOPICS[tech][0])
        
        # é‡è¤‡å‰Šé™¤ãƒ»å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆ
        unique_topics = list(dict.fromkeys(topics))
        
        # Zennäººæ°—åº¦ã«åŸºã¥ãå„ªå…ˆåº¦
        priority_topics = ["python", "javascript", "react", "ai", "typescript", "nodejs"]
        sorted_topics = sorted(unique_topics, key=lambda x: 
                             priority_topics.index(x) if x in priority_topics else 100)
        
        return sorted_topics[:ZENN_OPTIMAL_CONFIG["max_topics"]]
    
    def create_zenn_optimized_prompt(self, logs: List[Dict], tech_analysis: Dict) -> str:
        """Zennæœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        
        log_summary = []
        for log in logs[-15:]:  # æœ€æ–°15ä»¶
            timestamp = log.get("timestamp", "")
            log_type = log.get("type", "")
            message = log.get("message", "")
            log_summary.append(f"{timestamp}: [{log_type}] {message}")
        
        primary_techs = ", ".join(tech_analysis["primary_tech"])
        complexity = tech_analysis["complexity_level"]
        suggested_topics = self.generate_zenn_topics(tech_analysis)
        suggested_emoji = self.select_optimal_emoji(tech_analysis)
        
        prompt = f"""
ã‚ãªãŸã¯Zennç‰¹åŒ–ã®æŠ€è¡“è¨˜äº‹ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®é–‹ç™ºãƒ­ã‚°ã‚’åˆ†æã—ã¦ã€Zennã§äººæ°—ãŒå‡ºã‚‹é«˜å“è³ªãªæŠ€è¡“è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## æŠ€è¡“åˆ†æçµæœ
- ä¸»è¦æŠ€è¡“: {primary_techs}
- è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«: {complexity}
- æ¨å¥¨topics: {suggested_topics}
- æ¨å¥¨emoji: {suggested_emoji}

## é–‹ç™ºãƒ­ã‚°ï¼ˆæœ€æ–°15ä»¶ï¼‰
{chr(10).join(log_summary)}

## Zennè¨˜äº‹æœ€é©åŒ–è¦ä»¶
1. **ã‚¿ã‚¤ãƒˆãƒ«**: SEOæœ€é©åŒ–ãƒ»å…·ä½“çš„ãƒ»é­…åŠ›çš„ï¼ˆ30-60æ–‡å­—ï¼‰
2. **æ–‡å­—æ•°**: {ZENN_OPTIMAL_CONFIG["optimal_word_count"]}æ–‡å­—ç¨‹åº¦
3. **æ§‹æˆ**: å°å…¥â†’å•é¡Œâ†’è§£æ±ºâ†’ã‚³ãƒ¼ãƒ‰ä¾‹â†’å­¦ã³â†’ã¾ã¨ã‚
4. **å®Ÿç”¨æ€§**: èª­è€…ãŒå®Ÿéš›ã«è©¦ã›ã‚‹å†…å®¹
5. **ç‹¬è‡ªæ€§**: å®Ÿä½“é¨“ã«åŸºã¥ãçŸ¥è¦‹ãƒ»ãƒãƒã£ãŸç‚¹ãƒ»è§£æ±ºæ³•
6. **å¯èª­æ€§**: è¦‹å‡ºã—ãƒ»ç®‡æ¡æ›¸ããƒ»ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é©åˆ‡ä½¿ç”¨

## é«˜å“è³ªè¨˜äº‹ã®ç‰¹å¾´
- å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã¨ãã®èª¬æ˜
- å®Ÿéš›ã«ãƒãƒã£ãŸå•é¡Œã¨è§£æ±ºéç¨‹
- ãªãœãã®æ–¹æ³•ã‚’é¸ã‚“ã ã‹ã®ç†ç”±
- ä»–ã®æ‰‹æ³•ã¨ã®æ¯”è¼ƒãƒ»æ¤œè¨
- èª­è€…ã¸ã®æ˜ç¢ºãªãƒ¡ãƒªãƒƒãƒˆ

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
```json
{{
    "title": "å®Ÿè·µçš„ã§é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ30-60æ–‡å­—ï¼‰",
    "emoji": "{suggested_emoji}",
    "type": "tech",
    "topics": {json.dumps(suggested_topics, ensure_ascii=False)},
    "published": false,
    "content": "è¨˜äº‹æœ¬æ–‡ï¼ˆMarkdownå½¢å¼ï¼‰",
    "estimated_reading_time": "3-5åˆ†",
    "target_audience": "åˆå¿ƒè€…|ä¸­ç´šè€…|ä¸Šç´šè€…",
    "key_takeaways": ["å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ1", "å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ2", "å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ3"]
}}
```

è¨˜äº‹æœ¬æ–‡ã®æ§‹æˆä¾‹ï¼š
# ã‚¿ã‚¤ãƒˆãƒ«

## ã¯ã˜ã‚ã«
ãªãœã“ã®è¨˜äº‹ã‚’æ›¸ãã‹ãƒ»èª­è€…ã«ã©ã‚“ãªãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚‹ã‹

## å•é¡Œãƒ»èª²é¡Œ
å®Ÿéš›ã«é­é‡ã—ãŸå•é¡Œãƒ»ãªãœãã®å•é¡ŒãŒé‡è¦ã‹

## è§£æ±ºæ–¹æ³•
å…·ä½“çš„ãªå®Ÿè£…ãƒ»ã‚³ãƒ¼ãƒ‰ä¾‹ãƒ»æ‰‹é †

```python
# å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ä¾‹
def example_function():
    return "å…·ä½“çš„ã§å‹•ä½œã™ã‚‹ä¾‹"
```

## ãƒãƒã£ãŸãƒã‚¤ãƒ³ãƒˆ
å®Ÿéš›ã«ãƒãƒã£ãŸç‚¹ãƒ»è§£æ±ºã«æ™‚é–“ãŒã‹ã‹ã£ãŸç†ç”±

## ä»–ã®æ–¹æ³•ã¨ã®æ¯”è¼ƒ
ãªãœã“ã®æ–¹æ³•ã‚’é¸ã‚“ã ã‹ãƒ»ä»–ã®é¸æŠè‚¢

## å­¦ã‚“ã ã“ã¨ãƒ»ãƒã‚¤ãƒ³ãƒˆ
ä»Šå›ã®ä½“é¨“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãƒ»æ³¨æ„ç‚¹

## ã¾ã¨ã‚
è¦ç‚¹ã®æ•´ç†ãƒ»æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ»èª­è€…ã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹

å®Ÿä½“é¨“ã«åŸºã¥ãã€èª­è€…ãŒå®Ÿéš›ã«å®Ÿè£…ã§ãã‚‹å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    
    def generate_article(self, logs: List[Dict]) -> Optional[Dict[str, Any]]:
        """Zennæœ€é©åŒ–AIè¨˜äº‹ç”Ÿæˆ"""
        if not self.client:
            print("âŒ Claude APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
            
        if len(logs) < 5:
            print(f"âŒ ãƒ­ã‚°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½5ä»¶å¿…è¦ã€ç¾åœ¨{len(logs)}ä»¶ï¼‰")
            return None
        
        print("ğŸ¤– Zennæœ€é©åŒ–AIè¨˜äº‹ç”Ÿæˆä¸­...")
        
        tech_analysis = self.analyze_technical_domains(logs)
        prompt = self.create_zenn_optimized_prompt(logs, tech_analysis)
        
        try:
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )
            
            content = response.content[0].text
            print(f"ğŸ“„ AIå¿œç­”é•·: {len(content)}æ–‡å­—")
            
            # JSONæŠ½å‡ºï¼ˆã‚ˆã‚Šå …ç‰¢ï¼‰
            json_matches = re.findall(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if not json_matches:
                json_matches = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            
            if json_matches:
                try:
                    article_data = json.loads(json_matches[0])
                    return self.validate_article_quality(article_data)
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
                    return None
            else:
                print("âŒ AIã®å‡ºåŠ›ã‹ã‚‰JSONã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                print("ãƒ‡ãƒãƒƒã‚°ç”¨å‡ºåŠ›:")
                print(content[:500] + "...")
                return None
                
        except Exception as e:
            print(f"âŒ AIè¨˜äº‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def validate_article_quality(self, article_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è¨˜äº‹å“è³ªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        quality_issues = []
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
        required_fields = ["title", "emoji", "type", "topics", "content"]
        for field in required_fields:
            if not article_data.get(field):
                quality_issues.append(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸è¶³: {field}")
        
        # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        content = article_data.get("content", "")
        word_count = len(content)
        if word_count < ZENN_OPTIMAL_CONFIG["min_word_count"]:
            quality_issues.append(f"æ–‡å­—æ•°ä¸è¶³: {word_count}æ–‡å­—ï¼ˆæœ€ä½{ZENN_OPTIMAL_CONFIG['min_word_count']}æ–‡å­—ï¼‰")
        elif word_count > ZENN_OPTIMAL_CONFIG["max_word_count"]:
            quality_issues.append(f"æ–‡å­—æ•°éå¤š: {word_count}æ–‡å­—ï¼ˆæœ€å¤§{ZENN_OPTIMAL_CONFIG['max_word_count']}æ–‡å­—ï¼‰")
        
        # ãƒˆãƒ”ãƒƒã‚¯æ•°ãƒã‚§ãƒƒã‚¯
        topics = article_data.get("topics", [])
        if len(topics) < ZENN_OPTIMAL_CONFIG["min_topics"]:
            quality_issues.append(f"ãƒˆãƒ”ãƒƒã‚¯ä¸è¶³: {len(topics)}å€‹ï¼ˆæœ€ä½{ZENN_OPTIMAL_CONFIG['min_topics']}å€‹ï¼‰")
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆæŠ€è¡“è¨˜äº‹ã®å ´åˆï¼‰
        if article_data.get("type") == "tech" and "```" not in content:
            quality_issues.append("æŠ€è¡“è¨˜äº‹ã«ã‚³ãƒ¼ãƒ‰ä¾‹ãŒã‚ã‚Šã¾ã›ã‚“")
        
        if quality_issues:
            print("âš ï¸ å“è³ªå•é¡Œã‚’æ¤œå‡º:")
            for issue in quality_issues:
                print(f"   - {issue}")
            
            # è‡´å‘½çš„ãªå•é¡ŒãŒã‚ã‚‹å ´åˆã¯è¨˜äº‹ã‚’ç ´æ£„
            if len(quality_issues) > 2:
                print("âŒ å“è³ªå•é¡ŒãŒå¤šã™ãã‚‹ãŸã‚è¨˜äº‹ã‚’ç ´æ£„")
                return None
        
        # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        quality_score = 1.0 - (len(quality_issues) * 0.2)
        article_data["quality_score"] = max(quality_score, 0.0)
        
        print(f"âœ… è¨˜äº‹å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.2f}")
        return article_data
    
    def save_zenn_article(self, article_data: Dict[str, Any]) -> Optional[Path]:
        """Zennæœ€é©åŒ–è¨˜äº‹ä¿å­˜"""
        if not article_data:
            return None
            
        title = article_data.get("title", "Untitled")
        safe_title = re.sub(r'[^\w\s-]', '', title).replace(' ', '_')[:50]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Zennè¨˜äº‹ç”¨ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆSEOæœ€é©åŒ–ï¼‰
        slug = f"{timestamp}_{safe_title.lower()}"
        filename = f"{slug}.md"
        file_path = Path(PROJECT_ARTICLES_PATH) / filename
        
        # Zennæœ€é©åŒ–ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼
        post = frontmatter.Post(
            content=article_data.get("content", ""),
            title=title,
            emoji=article_data.get("emoji", "ğŸ“"),
            type=article_data.get("type", "tech"),
            topics=article_data.get("topics", []),
            published=False,  # å“è³ªç¢ºèªå¾Œã«æ‰‹å‹•ã§true
            created_at=datetime.now().isoformat(),
            quality_score=article_data.get("quality_score", 0.0),
            estimated_reading_time=article_data.get("estimated_reading_time", "3-5åˆ†"),
            target_audience=article_data.get("target_audience", "ä¸­ç´šè€…"),
            key_takeaways=article_data.get("key_takeaways", []),
            source="zenn_optimized_ai",
            slug=slug
        )
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                frontmatter.dump(post, f)
            print(f"âœ… Zennæœ€é©åŒ–è¨˜äº‹ã‚’ä¿å­˜: {file_path}")
            return file_path
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def generate_and_save(self) -> bool:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šè¨˜äº‹ç”Ÿæˆã¨ä¿å­˜"""
        print("ğŸš€ Zennæœ€é©åŒ–AIè¨˜äº‹ç”Ÿæˆã‚’é–‹å§‹...")
        
        logs = self.get_recent_logs(days=7)
        
        if not logs:
            print("âŒ ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("å…ˆã« dev_log_watcher.py ã‚’å®Ÿè¡Œã—ã¦ãƒ­ã‚°ã‚’è“„ç©ã—ã¦ãã ã•ã„")
            return False
        
        print(f"ğŸ“Š {len(logs)}ä»¶ã®ãƒ­ã‚°ã‚’åˆ†æä¸­...")
        
        article_data = self.generate_article(logs)
        if article_data:
            saved_path = self.save_zenn_article(article_data)
            if saved_path:
                print(f"\nğŸ‰ Zennæœ€é©åŒ–è¨˜äº‹ç”Ÿæˆå®Œäº†!")
                print(f"   ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«: {article_data.get('title')}")
                print(f"   {article_data.get('emoji')} Topics: {', '.join(article_data.get('topics', []))}")
                print(f"   ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {article_data.get('quality_score', 0.0):.2f}")
                print(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {saved_path}")
                print(f"\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
                print(f"1. ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã®å†…å®¹ã‚’ç¢ºèªãƒ»ç·¨é›†")
                print(f"2. published: true ã«å¤‰æ›´")
                print(f"3. git add articles/ && git commit -m 'ğŸ“ æ–°è¨˜äº‹è¿½åŠ '")
                print(f"4. git push origin main ã§è‡ªå‹•æŠ•ç¨¿")
                print(f"5. Zenn: https://zenn.dev/daideguchi ã§ç¢ºèª")
                return True
        
        return False

def main():
    print("ğŸš€ Zennæœ€é©åŒ–AIè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print(f"â° å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    generator = ZennOptimizedGenerator()
    success = generator.generate_and_save()
    
    if not success:
        print("\nâŒ è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
        print("- ANTHROPIC_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
        print("- ååˆ†ãªãƒ­ã‚°ãŒè“„ç©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆæœ€ä½5ä»¶ï¼‰")
        print("- python3 automation/dev_log_watcher.py ã‚’å…ˆã«å®Ÿè¡Œ")
        print("- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª")

if __name__ == "__main__":
    main()